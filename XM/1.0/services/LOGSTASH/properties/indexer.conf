input {
  redis {
    host => "10.3.172.113"
    data_type => "list"
    port => "6379"
    key => "logstash:redis:test"
    type => "redis-input"
    threads => 15
  }
}


filter {

  translate {
    field => "host"
    destination => "business"
    dictionary_path => "/etc/logstash/business_map.yml"
    refresh_interval => 60
    fallback => "unknown"
  }

  translate {
    field => "module_tag"
    destination => "module"
    dictionary_path => "/etc/logstash/module_map.yml"
    refresh_interval => 60
    fallback => "unknown"
    remove_field => ["module_tag"]
  }



  if [type] == "jetty_log" or [type] == "business_log" {
    ruby{
      init => "@kname = ['date','time','level','messages']"
      code => "
              msgArr = event.get('message').split(' ', 4)
              v = {'info' => Hash[@kname.zip(msgArr)]}
              new_event = LogStash::Event.new(v)
              new_event.remove('@timestamp')
              event.append(new_event)
              "
      add_field => ["logdate", "%{info[date]} %{info[time]}"]
      remove_field => ["message"]
      }
      date {
        match => ["logdate", "yyyy-MM-dd HH:mm:ss,SSS"]
        remove_field => ["logdate","info[date]","info[time]"]
    }
    }


  if [type] == "nginx_log" {
    grok{
        patterns_dir => ["/etc/logstash/patterns"]
        match => {"message" => "%{NGINXACCESS}"}
        add_field => ["logdate", "%{timestamp}"]
        remove_field => ["message"]
    }
    date{
       match => ["logdate", "ISO8601"]
       remove_field => ["logdate", "timestamp"]
    }
  }

}

output {
  elasticsearch {
      hosts => ["10.3.138.60:9200", "10.3.138.50:9200", "10.3.155.153:9200"]
      index => "es6-ns-%{+YYYY.MM.dd}"
      retry_on_conflict => 3
      retry_initial_interval => 8
  }
}