<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration supports_adding_forbidden="true">

    <property require-input="true">
        <name>download_url</name>
        <value>http://yum.example.com/hadoop/kafka_2.12-1.0.0.tgz</value>
        <description>下载路径</description>
    </property>
    <property require-input="true">
        <name>install_dir</name>
        <value>/opt/kafka</value>
        <description>安装目录</description>
    </property>

    <property>
        <name>kafka_user</name>
        <display-name>Kafka User</display-name>
        <value>kafka</value>
        <property-type>USER</property-type>
        <description/>
        <value-attributes>
            <type>user</type>
            <overridable>false</overridable>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kafka_keytab</name>
        <description>Kafka keytab path</description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kafka_principal_name</name>
        <description>Kafka principal name</description>
        <property-type>KERBEROS_PRINCIPAL</property-type>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kafka_log_dir</name>
        <value>/var/log/kafka</value>
        <description/>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kafka_pid_dir</name>
        <value>/var/run/kafka</value>
        <display-name>Kafka PID dir</display-name>
        <description/>
        <value-attributes>
            <type>directory</type>
            <editable-only-at-install>true</editable-only-at-install>
            <overridable>false</overridable>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kafka_user_nofile_limit</name>
        <value>1280000</value>
        <description>Max open files limit setting for KAFKA user.</description>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kafka_user_nproc_limit</name>
        <value>65536</value>
        <description>Max number of processes limit setting for KAFKA user.</description>
        <on-ambari-upgrade add="true"/>
    </property>
    <!-- kafka-env.sh -->
    <property>
        <name>content</name>
        <display-name>kafka-env template</display-name>
        <description>This is the jinja template for kafka-env.sh file</description>
        <value>
#!/bin/bash

# Set KAFKA specific environment variables here.

# The java implementation to use.
export JAVA_HOME={{java64_home}}
export PATH=$PATH:$JAVA_HOME/bin
export PID_DIR={{kafka_pid_dir}}
export LOG_DIR={{kafka_log_dir}}
export KAFKA_KERBEROS_PARAMS="{{kafka_kerberos_params}}"
# Add kafka sink to classpath and related depenencies
if [ -e "/usr/lib/ambari-metrics-kafka-sink/ambari-metrics-kafka-sink.jar" ]; then
    export CLASSPATH=$CLASSPATH:/usr/lib/ambari-metrics-kafka-sink/ambari-metrics-kafka-sink.jar
    export CLASSPATH=$CLASSPATH:/usr/lib/ambari-metrics-kafka-sink/lib/*
fi

# ranger
if [ -d "/opt/ranger-kafka-plugin" ]; then
    export CLASSPATH=${CLASSPATH}:/opt/ranger-kafka-plugin/lib/*
fi

if [ -f /etc/kafka/conf/kafka-ranger-env.sh ]; then
. /etc/kafka/kafka-ranger-env.sh
fi

        </value>
        <value-attributes>
            <type>content</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kafka-run-class-content</name>
        <display-name>kafka-run-class template</display-name>
        <description>This is template for kafka-run-class.sh file</description>
        <value><![CDATA[
if [ $# -lt 1 ];then
    echo "USAGE: $0 [-daemon] [-name servicename] [-loggc] classname [opts]"
    exit 1
fi

# CYGINW == 1 if Cygwin is detected, else 0.
if [[ $(uname -a) =~ "CYGWIN" ]]; then
    CYGWIN=1
else
    CYGWIN=0
fi

if [ -z "$INCLUDE_TEST_JARS" ]; then
    INCLUDE_TEST_JARS=false
fi

# Exclude jars not necessary for running commands.
regex="(-(test|src|scaladoc|javadoc)\.jar|jar.asc)$"
should_include_file() {
    if [ "$INCLUDE_TEST_JARS" = true ]; then
        return 0
    fi
    file=$1
    if [ -z "$(echo "$file" | egrep "$regex")" ] ; then
        return 0
    else
        return 1
    fi
}

base_dir=$(dirname $0)/..

if [ -z "$SCALA_VERSION" ]; then
    SCALA_VERSION=2.10.6
fi

if [ -z "$SCALA_BINARY_VERSION" ]; then
    SCALA_BINARY_VERSION=2.10
fi

# run ./gradlew copyDependantLibs to get all dependant jars in a local dir
shopt -s nullglob
for dir in "$base_dir"/core/build/dependant-libs-${SCALA_VERSION}*;
do
    if [ -z "$CLASSPATH" ] ; then
        CLASSPATH="$dir/*"
    else
        CLASSPATH="$CLASSPATH:$dir/*"
    fi
done

for file in "$base_dir"/examples/build/libs/kafka-examples*.jar;
do
    if should_include_file "$file"; then
        CLASSPATH="$CLASSPATH":"$file"
    fi
done

for file in "$base_dir"/clients/build/libs/kafka-clients*.jar;
do
    if should_include_file "$file"; then
        CLASSPATH="$CLASSPATH":"$file"
    fi
done

for file in "$base_dir"/streams/build/libs/kafka-streams*.jar;
do
    if should_include_file "$file"; then
        CLASSPATH="$CLASSPATH":"$file"
    fi
done

for file in "$base_dir"/streams/examples/build/libs/kafka-streams-examples*.jar;
do
    if should_include_file "$file"; then
        CLASSPATH="$CLASSPATH":"$file"
    fi
done

for file in "$base_dir"/streams/build/dependant-libs-${SCALA_VERSION}/rocksdb*.jar;
do
    CLASSPATH="$CLASSPATH":"$file"
done

for file in "$base_dir"/tools/build/libs/kafka-tools*.jar;
do
    if should_include_file "$file"; then
        CLASSPATH="$CLASSPATH":"$file"
    fi
done

for dir in "$base_dir"/tools/build/dependant-libs-${SCALA_VERSION}*;
do
    CLASSPATH="$CLASSPATH:$dir/*"
done

for cc_pkg in "api" "runtime" "file" "json" "tools"
do
    for file in "$base_dir"/connect/${cc_pkg}/build/libs/connect-${cc_pkg}*.jar;
    do
        if should_include_file "$file"; then
            CLASSPATH="$CLASSPATH":"$file"
        fi
    done
    if [ -d "$base_dir/connect/${cc_pkg}/build/dependant-libs" ] ; then
        CLASSPATH="$CLASSPATH:$base_dir/connect/${cc_pkg}/build/dependant-libs/*"
    fi
done

# classpath addition for release
for file in "$base_dir"/libs/*;
do
    if should_include_file "$file"; then
        CLASSPATH="$CLASSPATH":"$file"
    fi
done

for file in "$base_dir"/core/build/libs/kafka_${SCALA_BINARY_VERSION}*.jar;
do
    if should_include_file "$file"; then
        CLASSPATH="$CLASSPATH":"$file"
    fi
done
shopt -u nullglob

# JMX settings
if [ -z "$KAFKA_JMX_OPTS" ]; then
    KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false "
fi

# JMX port to use
if [ $JMX_PORT ]; then
    KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT "
fi

# Log directory to use
if [ "x$LOG_DIR" = "x" ]; then
    LOG_DIR="$base_dir/logs"
fi

# Log4j settings
if [ -z "$KAFKA_LOG4J_OPTS" ]; then
    # Log to console. This is a tool.
    LOG4J_DIR="$base_dir/config/tools-log4j.properties"
    # If Cygwin is detected, LOG4J_DIR is converted to Windows format.
    (( CYGWIN )) && LOG4J_DIR=$(cygpath --path --mixed "${LOG4J_DIR}")
    KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:${LOG4J_DIR}"
else
    # create logs directory
    if [ ! -d "$LOG_DIR" ]; then
        mkdir -p "$LOG_DIR"
    fi
fi

# If Cygwin is detected, LOG_DIR is converted to Windows format.
(( CYGWIN )) && LOG_DIR=$(cygpath --path --mixed "${LOG_DIR}")
KAFKA_LOG4J_OPTS="-Dkafka.logs.dir=$LOG_DIR $KAFKA_LOG4J_OPTS"

# Generic jvm settings you want to add
if [ -z "$KAFKA_OPTS" ]; then
    KAFKA_OPTS=""
fi

# Set Debug options if enabled
if [ "x$KAFKA_DEBUG" != "x" ]; then

    # Use default ports
    DEFAULT_JAVA_DEBUG_PORT="5005"

    if [ -z "$JAVA_DEBUG_PORT" ]; then
        JAVA_DEBUG_PORT="$DEFAULT_JAVA_DEBUG_PORT"
    fi

    # Use the defaults if JAVA_DEBUG_OPTS was not set
    DEFAULT_JAVA_DEBUG_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=${DEBUG_SUSPEND_FLAG:-n},address=$JAVA_DEBUG_PORT"
    if [ -z "$JAVA_DEBUG_OPTS" ]; then
        JAVA_DEBUG_OPTS="$DEFAULT_JAVA_DEBUG_OPTS"
    fi

    echo "Enabling Java debug options: $JAVA_DEBUG_OPTS"
    KAFKA_OPTS="$JAVA_DEBUG_OPTS $KAFKA_OPTS"
fi

# Which java to use
if [ -z "$JAVA_HOME" ]; then
    JAVA="java"
else
    JAVA="$JAVA_HOME/bin/java"
fi

# Memory options
if [ -z "$KAFKA_HEAP_OPTS" ]; then
    KAFKA_HEAP_OPTS="-Xmx16384M"
fi

# JVM performance options
if [ -z "$KAFKA_JVM_PERFORMANCE_OPTS" ]; then
    KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true"
fi


while [ $# -gt 0 ]; do
    COMMAND=$1
    case $COMMAND in
        -name)
            DAEMON_NAME=$2
            CONSOLE_OUTPUT_FILE=$LOG_DIR/$DAEMON_NAME.out
            shift 2
            ;;
        -loggc)
            if [ -z "$KAFKA_GC_LOG_OPTS" ]; then
            GC_LOG_ENABLED="true"
            fi
            shift
            ;;
        -daemon)
            DAEMON_MODE="true"
            shift
            ;;
        *)
            break
            ;;
    esac
done

# GC options
GC_FILE_SUFFIX='-gc.log'
GC_LOG_FILE_NAME=''
if [ "x$GC_LOG_ENABLED" = "xtrue" ]; then
    GC_LOG_FILE_NAME=$DAEMON_NAME$GC_FILE_SUFFIX
    KAFKA_GC_LOG_OPTS="-Xloggc:$LOG_DIR/$GC_LOG_FILE_NAME -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps "
fi

# If Cygwin is detected, classpath is converted to Windows format.
(( CYGWIN )) && CLASSPATH=$(cygpath --path --mixed "${CLASSPATH}")

# Launch mode
if [ "x$DAEMON_MODE" = "xtrue" ]; then
    nohup $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_KERBEROS_PARAMS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS "$@" > "$CONSOLE_OUTPUT_FILE" 2>&1 < /dev/null &
else
    exec $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_KERBEROS_PARAMS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS "$@"
fi
echo $!>{{kafka_pid_dir}}/kafka.pid
        ]]>
        </value>
        <value-attributes>
            <type>content</type>
        </value-attributes>
        <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>is_supported_kafka_ranger</name>
        <value>true</value>
        <on-ambari-upgrade add="true"/>
    </property>

</configuration>
