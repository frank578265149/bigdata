<?xml version="1.0"?>
<metainfo>
  <schemaVersion>2.0</schemaVersion>
  <services>
    <service>
      <name>SPARK2</name>
      <displayName>Spark2</displayName>
      <comment>Apache Spark 2.0 is a fast and general engine for large-scale data processing.</comment>
      <version>2.2.0</version>
      <selection>TECH_PREVIEW</selection>
      <components>
        <component>
          <name>SPARK2_JOBHISTORYSERVER</name>
          <displayName>Spark2 History Server</displayName>
          <category>MASTER</category>
          <cardinality>1</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>HDFS/HDFS_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
               <name>MAPREDUCE2/MAPREDUCE2_CLIENT</name>
               <scope>host</scope>
               <auto-deploy>
                 <enabled>true</enabled>
               </auto-deploy>
            </dependency>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
             </auto-deploy>
           </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/job_history_server.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
          <logs>
            <log>
              <logId>spark2_jobhistory_server</logId>
              <primary>true</primary>
            </log>
          </logs>
        </component>
        <component>
          <name>SPARK2_THRIFTSERVER</name>
          <displayName>Spark2 Thrift Server</displayName>
          <category>SLAVE</category>
          <cardinality>0+</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>HDFS/HDFS_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
               <name>MAPREDUCE2/MAPREDUCE2_CLIENT</name>
               <scope>host</scope>
               <auto-deploy>
                 <enabled>true</enabled>
               </auto-deploy>
            </dependency>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>HIVE/HIVE_METASTORE</name>
              <scope>cluster</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/spark_thrift_server.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
          <logs>
            <log>
              <logId>spark2_thriftserver</logId>
              <primary>true</primary>
            </log>
          </logs>
        </component>
        <component>
          <name>SPARK2_CLIENT</name>
          <displayName>Spark2 Client</displayName>
          <category>CLIENT</category>
          <cardinality>1+</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>HDFS/HDFS_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
               <name>MAPREDUCE2/MAPREDUCE2_CLIENT</name>
               <scope>host</scope>
               <auto-deploy>
                 <enabled>true</enabled>
               </auto-deploy>
            </dependency>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
             </auto-deploy>
            </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/spark_client.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
          <configFiles>
            <configFile>
              <type>env</type>
              <fileName>spark-log4j.properties</fileName>
              <dictionaryName>spark2-log4j-properties</dictionaryName>
            </configFile>
            <configFile>
              <type>env</type>
              <fileName>spark-env.sh</fileName>
              <dictionaryName>spark2-env</dictionaryName>
            </configFile>
            <configFile>
              <type>env</type>
              <fileName>spark-metrics.properties</fileName>
              <dictionaryName>spark2-metrics-properties</dictionaryName>
            </configFile>
            <configFile>
              <type>properties</type>
              <fileName>spark-defaults.conf</fileName>
              <dictionaryName>spark2-defaults</dictionaryName>
            </configFile>
          </configFiles>
        </component>
        <component>
          <name>LIVY2_SERVER</name>
          <displayName>Livy for Spark2 Server</displayName>
          <category>SLAVE</category>
          <cardinality>0+</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>SPARK2/SPARK2_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>HDFS/HDFS_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/livy2_server.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
          <logs>
            <log>
              <logId>livy2_server</logId>
              <primary>true</primary>
            </log>
          </logs>
        </component>
      </components>

      <configuration-dependencies>
        <config-type>spark2-defaults</config-type>
        <config-type>spark2-env</config-type>
        <config-type>spark2-log4j-properties</config-type>
        <config-type>spark2-metrics-properties</config-type>
        <config-type>spark2-thrift-sparkconf</config-type>
        <config-type>spark2-hive-site-override</config-type>
        <config-type>spark2-thrift-fairscheduler</config-type>
        <config-type>livy2-conf</config-type>
        <config-type>livy2-env</config-type>
        <config-type>livy2-log4j-properties</config-type>
        <config-type>livy2-spark-blacklist</config-type>
      </configuration-dependencies>

      <commandScript>
        <script>scripts/service_check.py</script>
        <scriptType>PYTHON</scriptType>
        <timeout>300</timeout>
      </commandScript>

      <requiredServices>
        <service>HDFS</service>
        <service>YARN</service>
        <service>HIVE</service>
      </requiredServices>

      <quickLinksConfigurations>
        <quickLinksConfiguration>
          <fileName>quicklinks.json</fileName>
          <default>true</default>
        </quickLinksConfiguration>
      </quickLinksConfigurations>
    </service>
  </services>
</metainfo>
